# spatial_cnn part of two_stream_network
# Details:
#   bvlc_alexnet:
#   iter-0: loss ~= 4.6
#   iter-10,000: accuracy ~= 0.32

# meta info
name: "spatial_part_of_two_stream_cnn",
model: "alexnet",
# debug or fast(no summary)
run_mode: "debug"

# input info
input:
  # ucf101_rgb
  reader: "spatial_reader",
  num_class: 101,
  # input format: [height, width, channel]
  # "mean_npy": "/home/wsy/ckpt/vgg/VGG_mean.npy",
  raw_size: [256, 340, 3], # color image
  example_size: [227, 227, 3], # last dimension: color_channel * seq_len
  seq_len: 1 # num of frames

# sharing hyperparameters
batch_size: 256 # real_batch_size: batch_size / num_gpus / iter_size
iter_size: 4 # apply grads per iter_size inputs and that counts as 1 iteration.

# num of gpus when multi-gpus solver runs
gpus: [0, 1, 2, 3],
# iterations per summary for tensorboard
step_per_summary: 100,
# iterations per saving ckpt
step_per_ckpt: 1000,
# optimizer
optimizer:
  name: "Momentum",
  args:
    momentum: 0.9

# decay factor for learning_rate and weight decay
decay_factor: 0.1,
# Directory where to read model checkpoints
ckpt_dir: "/tmp/alexnet_rgb_train",

# train info
"@train":
  # content: path + label_id
  data_path: "./data/ucf_101/trainlist01.json"
  initial_learning_rate: 0.01
  # total iterations
  max_steps: 10000,
  # learning rate and weight decay decrease
  num_steps_per_decay: 4000,
  # checkpoint after train
  dest_dir: "/tmp/alexnet_rgb_train",
  # enqueue info
  input_queue:
    # "FIFO" or "shuffle" queue
    type: "FIFO",
    capacity: 100,
    num_thread: 10

# eval info
"@eval":
  # content: path + label_id
  data_path: "./data/ucf_101/testlist01.json",
  # Directory where to write event logs
  dest_dir: "/tmp/alexnet_rgb_test",
  # How often to run the eval if run_once == false
  eval_interval_secs: 300,
  # Number of examples to run
  num_examples: 1000,
  # top n precision
  top: 1,
  # Whether to run eval only once
  run_once: false,
  batch_size: 50,
  # enqueue info
  input_queue:
    # "FIFO" or "shuffle" queue
    type: "FIFO",
    capacity: 100,
    num_thread: 1
  # Below used for video_test.py
  # extract frames from video with equal space
  num_per_video: 25,

# graph info (Alexnet)
"layers": [
    "CONV_11x11_K96", "LRN", "POOL_3x3_S2", # [227, 227, 3] -> [55, 55, 96] -> [27, 27, 96]
    "CONV_5x5_K256", "LRN", "POOL_3x3_S2", # --> [13, 13, 256]
    "CONV_3x3_K384", # --> [13, 13, 384]
    "CONV_3x3_K384", # --> [13, 113, 384]
    "CONV_3x3_K256", "POOL_3x3_S2", # --> [13, 13, 256] -> [6, 6, 256]
    "FC_D4096", "DROPOUT",
    "FC_D4096", "DROPOUT",
  ],


    # Macros below
    # parameters-format in correspondence with Tensorflow_api
    "__define__": {
        "CONV_11x11_K96": {
            # input Shape [in_height, in_width, in_channels].
            "type": "conv2d",
            # filter Shape [filter_height, filter_width, in_channels, out_channels]
                # in_channels: RGB
                #          or optical flow (x or y)
                #          or number of last conv layer filters
                # out_channels: number of filters
            "filter": [11, 11, -1, 96],
            "init_stddev": 0.01,
            # same format with input
            "strides": [1, 4, 4, 1],
            # padding in two ways:
            # 1. [[height], [width]] (self-defined)
            # 2. 'SAME' or 'VALID'
            "padding": "VALID",
            # loss += weight_decay * l2(weights)
            "weight_decay": 0.0005
            # decrease sync with learning rate            # default follow with RELU
        },
        "CONV_5x5_K256": {
            "type": "conv2d",
            "filter": [5, 5, -1, 256],
            "init_stddev": 0.01,
            # same format with input
            "strides": [1, 1, 1, 1],
            # depth, height, width
            "padding": "SAME",
            "weight_decay": 0.0005
            # default follow with RELU
        },
        "CONV_3x3_K384": {
            "type": "conv2d",
            "filter": [3, 3, -1, 384],
            "init_stddev": 0.01,
            # same format with input
            "strides": [1, 1, 1, 1],
            # depth, height, width
            "padding": "SAME",
            "weight_decay": 0.0005
            # default follow with RELU
        },
        "CONV_3x3_K256": {
            "type": "conv2d",
            "filter": [3, 3, -1, 256],
            "init_stddev": 0.01,
            # same format with input
            "strides": [1, 1, 1, 1],
            # depth, height, width
            "padding": "SAME",
            "weight_decay": 0.0005
            # default follow with RELU
        },
        "POOL_3x3_S2": {
            "type": "max_pool2d",
            # first and last must '1'
            # middle: [height, width]
            "ksize": [1, 3, 3, 1],
            "strides": [1, 2, 2, 1],
            "padding": "VALID"
        },
        "LRN": {
            "type": "lrn",
            "depth_radius": 2,
            "alpha": 0.0001,
            "beta": 0.75
        },
        "FC_D4096": {
            "type": "fc",
            # -1 means auto-compute
            "shape": [-1, 4096],
            "init_stddev": 0.005, # init for weights
            "init_bias": 0.1,
            "weight_decay": 0.0005
            # default follow with RELU
        },
        "DROPOUT": {
            "type": "dropout",
            "prob": 0.5
        }
    }
}
