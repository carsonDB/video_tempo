{
    // meta info
    "name": "ucf101_rgb",
    "type": "cnn",
    // input info
    "input": {
        "type": "video",
        // exitence form of data (frames, clips)
        "read_from": "frames",
        "num_class": 101,
        // input will be resized to [height, width]
        "read_resolution": [128, 171],
        "clip_length": 16,
        // RGB or optical_flow
        "num_channel": 3
    },
    // enqueue info
    "input_queue": {
        // "FIFO" or "shuffle" queue
        "type": "FIFO",
        "capacity": 100,
        // "min_remain": 30,
        "num_reader": 10
    },

// sharing hyperparameters
    "batch_size": 30, // real: batch_size / num_gpus
    // num of gpus
    "num_gpus": 4,
    // optimizer
    "momentum": 0.9,
    // decay factor for learning_rate and weight decay
    "decay_factor": 0.1,
    // The decay to use for the moving average
    "moving_average_decay": 0.9999,
    // Directory where to read model checkpoints
    "checkpoint_dir": "/tmp/ucf101_rgb_train",

    // train info
    "train": {
        // content: path + label_id
        "lst_path": "/home/user/data/train_rgb_ucf101_sp1.lst",
        "initial_learning_rate": 0.003, 
        // total iterations
        "max_steps": 60000,
        // learning rate and weight decay decrease
        "num_steps_per_decay": 20000,
        // checkpoint after train
        "train_dir": "/tmp/ucf101_rgb_train",
        // preprocess info (pipeline)
        "preproc": [{
                "name": "subtract_mean"
            }, {
                "name": "random_crop",
                // [depth(time), height, width, in-channels]
                "size": [16, 112, 112, 3]
            }, {
             "name": "flip_left_right",
             "prob": 0.5
            }
        ]
    },  
    // eval info
    "eval": {
        // content: path + label_id
        "lst_path": "/home/user/data/test_rgb_ucf101_sp1.lst",
        // How often to run the eval if run_once == false
        "eval_interval_secs": 300,
        // Number of examples to run
        "num_examples": 4000,
        // top n precision
        "top": 1,
        // Whether to run eval only once
        "run_once": false,
        "num_examples_per_epoch": 4000,
        // Directory where to write event logs
        "eval_dir": "/tmp/ucf101_rgb_eval",
        // preprocess info (pipeline)
        "preproc": [{
                "name": "subtract_mean"
            }, {
                "name": "test_crop",
                // [height, width]
                "size": [112, 112]
            },
            // maybe shouldn't
            {
             "name": "flip_left_right",
             "prob": 0.5
            }
        ]
    },

    // graph info
    "graph": [
        // K64: 64 kernels
        // T1: temporal depth == 1
        "CONV3_K64", "POOL3_T1",
        "CONV3_K128", "POOL3_T2",
        
        "CONV3_K256", "POOL3_T2",
        "CONV3_K256", "POOL3_T2",
        "CONV3_K256", "POOL3_T2",
        
        "FC", "DROPOUT",
        "FC", "DROPOUT"
    ],
    
    // output logits
    "out_port": {
        "last_fc": 5
    },

    // Macros below
    // parameters-format in correspondence with Tensorflow_api
    "__define__": {

        "CONV3_K64": {
            // input Shape [in_depth, in_height, in_width, in_channels].
            // output Shape ==? input Shape
            "type": "conv3d",
            // filter Shape [filter_depth, filter_height, filter_width, in_channels, out_channels]
                // in_channels: RGB 
                //          or optical flow (x or y) 
                //          or number of last conv layer filters
                // out_channels: number of filters
            "filter": [3, 3, 3, -1, 64],
            "init_stddev": 0.01,
            // same format with input
            "strides": [1, 1, 1, 1, 1],
            // depth, height, width
            "padding": [[1, 1], [1, 1], [1, 1]],
            "weight_decay": 0.005
            // default follow with RELU
        },
        "CONV3_K128": {
            // input Shape [in_depth, in_height, in_width, in_channels].
            // output Shape ==? input Shape
            "type": "conv3d",
            // filter Shape [filter_depth, filter_height, filter_width, in_channels, out_channels]
                // in_channels: RGB 
                //          or optical flow (x or y) 
                //          or number of last conv layer filters
                // out_channels: number of filters
            "filter": [3, 3, 3, -1, 128],
            "init_stddev": 0.01,
            // same format with input
            "strides": [1, 1, 1, 1, 1],
            // depth, height, width
            "padding": [[1, 1], [1, 1], [1, 1]],
            "weight_decay": 0.005
            // default follow with RELU
        },
        "CONV3_K256": {
            // input Shape [in_depth, in_height, in_width, in_channels].
            // output Shape ==? input Shape
            "type": "conv3d",
            // filter Shape [filter_depth, filter_height, filter_width, in_channels, out_channels]
                // in_channels: RGB 
                //          or optical flow (x or y) 
                //          or number of last conv layer filters
                // out_channels: number of filters
            "filter": [3, 3, 3, -1, 256],
            "init_stddev": 0.01,
            // same format with input
            "strides": [1, 1, 1, 1, 1],
            // depth, height, width
            "padding": [[1, 1], [1, 1], [1, 1]],
            "weight_decay": 0.005
            // default follow with RELU
        },
        
        "POOL3_T1": {
            "type": "max_pool3d",
            // first and last must '1'
            // middle: [depth, height, width]
            "ksize": [1, 1, 2, 2, 1],
            "strides": [1, 1, 2, 2, 1],
            "padding": "VALID"
        },
        "POOL3_T2": {
            "type": "max_pool3d",
            // first and last must '1'
            "ksize": [1, 2, 2, 2, 1],
            "strides": [1, 2, 2, 2, 1],
            "padding": "VALID"
        },

        // // local response normalization
        // "LRN": {
        //  "type": "lrn",
        //  "depth_radius": 4,
        //  "bias": 1.0,
        //  "alpha": ,
        // },

        "FC": {
            "type": "fc",
            // -1 means auto-compute
            "shape": [-1, 2048],
            "init_stddev": 0.005,
            "weight_decay": 0.005 // decrease sync with learning rate
            // default follow with RELU
        },
        "DROPOUT": {
            "type": "dropout",
            "prob": 0.5
        }
    }
}
